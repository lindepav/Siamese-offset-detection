{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 608 images loaded in 0.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "consolidated_jpgdir = '/mnt/data/style_transfers/datasets/consolidated/jpg/'\n",
    "selected_traversals = ['A000', 'A003', 'A058', 'A059', 'A064', 'A155', 'A159', 'A035', 'A037', 'A079', 'A086', 'A150', 'A151', 'A025', 'A026', 'A062', 'A063', 'A064', 'A138']\n",
    "filenames = []\n",
    "for traversal in selected_traversals:\n",
    "    filenames += [img for img in glob.glob(consolidated_jpgdir + \"*\" + traversal + \"*.jpg\")]\n",
    "filenames = sorted(filenames)\n",
    "traversal_idx = i = 0\n",
    "images = np.zeros((len(filenames)//32, 32), dtype=object)\n",
    "start = time.time()\n",
    "for filename in filenames:\n",
    "    images[traversal_idx, i] = filename\n",
    "    i += 1\n",
    "    if i == 32:\n",
    "        traversal_idx += 1\n",
    "        i = 0\n",
    "print ('[INFO] {} images loaded in {:.1f} seconds.'.format(len(filenames), (time.time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the horizontal offset from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Ground truth loaded.\n"
     ]
    }
   ],
   "source": [
    "consolidated_gtdir = '/mnt/data/style_transfers/datasets/consolidated/gt/'\n",
    "gt = np.zeros((len(filenames)//32, 32), dtype=int)\n",
    "#consolidated_gt = consolidated_gtdir + \"A*_GT.txt\"\n",
    "gt_filenames = []\n",
    "for traversal in selected_traversals:\n",
    "    gt_filenames += [gt for gt in glob.glob(consolidated_gtdir + traversal + \"_GT.txt\")]\n",
    "gt_filenames = sorted(gt_filenames)\n",
    "traversal_idx = j = 0\n",
    "for filename in gt_filenames:\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = f.read()\n",
    "    data = data.split(\"\\n\")\n",
    "    data = list(filter(None, data))\n",
    "    for j, col in enumerate(data):\n",
    "        (horizontal, _) = [int(k) for k in col.split(\" \")]\n",
    "        gt[traversal_idx, j] = horizontal \n",
    "    traversal_idx += 1\n",
    "print(\"[INFO] Ground truth loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.072945019358431 -0.5 -113 376\n"
     ]
    }
   ],
   "source": [
    "gt_ = [list(filter(lambda x: x < 500 and x > -500, traversal)) for traversal in gt]\n",
    "gt_mean = np.mean([np.mean(gt__) for gt__ in gt_])\n",
    "gt_median = np.median([np.median(gt__) for gt__ in gt_])\n",
    "gt_min = np.min([np.min(gt__) for gt__ in gt_])\n",
    "gt_max = np.max([np.max(gt__) for gt__ in gt_])\n",
    "\n",
    "print(gt_mean, gt_median, gt_min, gt_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding the image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 4, 8, 16, 47, 188, 376px slide window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cv2_imshow(a, title=None, mode=None, i=None, j=None, k=None, **kwargs):\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    #a = cv2.rotate(a, cv2.ROTATE_90_CLOCKWISE)\n",
    "    # cv2 stores colors as BGR; convert to RGB\n",
    "    if a.ndim == 3:\n",
    "        if a.shape[2] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "    if mode == 'subplot':\n",
    "        plt.subplot(i, j, k)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "    else:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title(title)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "def imshow(a, title=None, mode=None, i=None, j=None, k=None, **kwargs):\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    if mode == 'subplot':\n",
    "        plt.subplot(i, j, k)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "    else:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title(title)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "def process_image(img):\n",
    "    x = np.resize(img, (224,224))\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "def read_image(img_path):\n",
    "    #img = kimage.load_img(img_path, target_size=(224, 224))\n",
    "    img = kimage.load_img(img_path)\n",
    "    x = kimage.img_to_array(img)\n",
    "    return x\n",
    "def get_slices(img_path, offset, slides_count, mode='pos'):\n",
    "    a = np.zeros((slides_count))\n",
    "    for i in range(0, slides_count):\n",
    "        if mode == 'pos':\n",
    "            a[i] = i*offset\n",
    "        elif mode == 'neg':\n",
    "            a[i] = -i*offset\n",
    "    return a\n",
    "def slide_image(img, offset):\n",
    "    if offset > 0:\n",
    "        img[:,:int(i*offset)] = (228, 35, 157)\n",
    "    else:\n",
    "        img[:,:int(-i*offset)] = (228, 35, 157)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(images, gt, offset, threshold, slides_count):\n",
    "    # initialize two empty lists to hold the (image, image) pairs and\n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    pairImagePaths = []\n",
    "    pairOffsets = []\n",
    "    pairLabels = []\n",
    "    \n",
    "    # loop over all images\n",
    "    for traversal_idx in range(len(images)):\n",
    "        if traversal_idx == 0:\n",
    "            continue\n",
    "        for i in range(32):\n",
    "            target_gt = gt[traversal_idx, i]\n",
    "            if abs(target_gt) > 300:\n",
    "                continue\n",
    "            base_path = images[0, i]          \n",
    "            target_path = images[traversal_idx, i]\n",
    "            if offset >= 0:     \n",
    "                slides = get_slices(base_path, offset, slides_count)    \n",
    "                for j, base_slide in enumerate(slides):\n",
    "                    pairImagePaths.append([base_path, target_path])\n",
    "                    pairOffsets.append([base_slide, 0])\n",
    "                    if abs(abs(target_gt) - j*offset) < threshold:\n",
    "                        pairLabels.append([1])\n",
    "                    else:\n",
    "                        pairLabels.append([0])\n",
    "            else:\n",
    "                slides = get_slices(target_path, offset, slides_count, mode='neg')  \n",
    "                for j, target_slide in enumerate(slides):\n",
    "                    pairImagePaths.append([base_path, target_path])\n",
    "                    pairOffsets.append([0, target_slide])\n",
    "                    if abs(abs(target_gt) - j*offset) < threshold:\n",
    "                        pairLabels.append([1])\n",
    "                    else:\n",
    "                        pairLabels.append([0])\n",
    "\n",
    "    return (np.array(pairImagePaths), np.array(pairOffsets), np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the Siamese NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained VGG16 'sister' network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_VGG16_model(input_shape):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected componenets and other help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    (featsA, featsB) = vectors\n",
    "    # compute the sum of squared distances between the vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
    "    # return the euclidean distance between the vectors\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 20\n",
    "threshold = 40\n",
    "slides_count = 10\n",
    "batch_size = 250\n",
    "epochs = 10\n",
    "IMG_SHAPE = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5470 pairs of image paths with offsets were generated in 0.1 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "(imagePathTrain, offsetTrain, labelTrain) = make_pairs(images, gt, offset, threshold, slides_count)\n",
    "print ('[INFO] {} pairs of image paths with offsets were generated in {:.1f} seconds.'.format(len(imagePathTrain), (time.time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_size = 10\n",
    "test_sample_size = 10\n",
    "train_indices = np.random.choice([i for i in range(0, len(imagePathTrain))], size=train_sample_size)\n",
    "test_indices = np.random.choice([i for i in range(0, len(imagePathTrain))], size=test_sample_size)\n",
    "test_indices = test_indices != train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairTrain = []\n",
    "for i in range(train_sample_size):\n",
    "    j = train_indices[i]\n",
    "    img1 = read_image(imagePathTrain[j, 0])\n",
    "    img2 = read_image(imagePathTrain[j, 1])\n",
    "    offset1 = offsetTrain[j, 0]\n",
    "    offset2 = offsetTrain[j, 1]\n",
    "    img1 = slide_image(img1, offset1)\n",
    "    imgg = slide_image(img2, offset2)\n",
    "    pairTrain.append([img1, img2])\n",
    "pairTrain = np.array(pairTrain)\n",
    "labelTrain = labelTrain[train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building siamese network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] building siamese network...\")\n",
    "IMG_SHAPE = (752,480,3)\n",
    "imgA = Input(shape=IMG_SHAPE)\n",
    "imgB = Input(shape=IMG_SHAPE)\n",
    "VGGfeatureExtractor = build_VGG16_model(IMG_SHAPE) # building the network only once since we want to share the weights \n",
    "featsA = VGGfeatureExtractor(imgA)\n",
    "featsB = VGGfeatureExtractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-c274175f6191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# finally, construct the siamese network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meuclidean_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatsA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatsB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m               \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             inputs, outputs = self._set_connectivity_metadata_(\n\u001b[0;32m--> 874\u001b[0;31m                 inputs, outputs, args, kwargs)\n\u001b[0m\u001b[1;32m    875\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_connectivity_metadata_\u001b[0;34m(self, inputs, outputs, args, kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m     \u001b[0;31m# This updates the layer history of the output tensor(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m     self._add_inbound_node(\n\u001b[0;32m-> 2038\u001b[0;31m         input_tensors=inputs, output_tensors=outputs, arguments=arguments)\n\u001b[0m\u001b[1;32m   2039\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_add_inbound_node\u001b[0;34m(self, input_tensors, output_tensors, arguments)\u001b[0m\n\u001b[1;32m   2052\u001b[0m     \"\"\"\n\u001b[1;32m   2053\u001b[0m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0;32m-> 2054\u001b[0;31m                                         input_tensors)\n\u001b[0m\u001b[1;32m   2055\u001b[0m     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\n\u001b[1;32m   2056\u001b[0m                                       input_tensors)\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   2051\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m     \"\"\"\n\u001b[0;32m-> 2053\u001b[0;31m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0m\u001b[1;32m   2054\u001b[0m                                         input_tensors)\n\u001b[1;32m   2055\u001b[0m     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "# finally, construct the siamese network\n",
    "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building siamese network...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-e21ff1242c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# finally, construct the siamese network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meuclidean_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatsA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatsB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m               \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             inputs, outputs = self._set_connectivity_metadata_(\n\u001b[0;32m--> 874\u001b[0;31m                 inputs, outputs, args, kwargs)\n\u001b[0m\u001b[1;32m    875\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_connectivity_metadata_\u001b[0;34m(self, inputs, outputs, args, kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m     \u001b[0;31m# This updates the layer history of the output tensor(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m     self._add_inbound_node(\n\u001b[0;32m-> 2038\u001b[0;31m         input_tensors=inputs, output_tensors=outputs, arguments=arguments)\n\u001b[0m\u001b[1;32m   2039\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_add_inbound_node\u001b[0;34m(self, input_tensors, output_tensors, arguments)\u001b[0m\n\u001b[1;32m   2052\u001b[0m     \"\"\"\n\u001b[1;32m   2053\u001b[0m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0;32m-> 2054\u001b[0;31m                                         input_tensors)\n\u001b[0m\u001b[1;32m   2055\u001b[0m     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\n\u001b[1;32m   2056\u001b[0m                                       input_tensors)\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/TensorFlow/2.0.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   2051\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m     \"\"\"\n\u001b[0;32m-> 2053\u001b[0;31m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0m\u001b[1;32m   2054\u001b[0m                                         input_tensors)\n\u001b[1;32m   2055\u001b[0m     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n",
    "    #validation_data=([pairTest[:, 0], pairTest[:, 1]], labelTest[:]),\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    epochs=epochs)\n",
    "\n",
    "#num_of_samples = features.shape[0]    \n",
    "#names = ['Correct offset', 'Wrong offset']\n",
    "#Y = np_utils.to_categorical(labels, names)\n",
    "#x,y = shuffle(features, Y, random_state=2)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model6.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "features1 = []\n",
    "features2 = []\n",
    "start = time.time()\n",
    "\n",
    "for j, pair in enumerate(pairTrain):\n",
    "    print(j+1, '/', train_sample_size)\n",
    "    img1 = pair[0]\n",
    "    img2 = pair[1]\n",
    "    feature_1, feature_2 = feature_extractor(img1,img2)\n",
    "    features1.append(feature_1)\n",
    "    features2.append(feature_2)\n",
    "features1 = tf.convert_to_tensor(features1)\n",
    "features2 = tf.convert_to_tensor(features2)\n",
    "print ('[INFO] {} pairs of features extracted in {:.1f} seconds.'.format(train_sample_size, (time.time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving siamese model...\")\n",
    "model.save(config.MODEL_PATH)\n",
    "# plot the training history\n",
    "print(\"[INFO] plotting training history...\")\n",
    "utils.plot_training(history, config.PLOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:], verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing\n",
    "features = dataset_testing()\n",
    "\n",
    "num_of_samples = features.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"model6.h5\")\n",
    "names = ['Change', 'No change']\n",
    "\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "x_test,y_test = shuffle(features,Y, random_state=2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
