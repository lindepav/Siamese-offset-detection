{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Lambda\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import scipy.spatial.distance\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 179 images loaded in 0.9 seconds.\n"
     ]
    }
   ],
   "source": [
    "def read_image(img_path):\n",
    "    #img = kimage.load_img(img_path, target_size=(224, 224))\n",
    "    img = kimage.load_img(img_path)\n",
    "    x = kimage.img_to_array(img)\n",
    "    return x\n",
    "start = time.time()\n",
    "consolidated_jpgdir = '/mnt/data/style_transfers/datasets/consolidated/jpg/'\n",
    "#selected_traversals = ['A000', 'A003', 'A058', 'A059', 'A064', 'A155', 'A159', 'A035', 'A037', 'A079', 'A086', 'A150', 'A151', 'A025', 'A026', 'A062', 'A063', 'A064', 'A138']\n",
    "filenames = [img for img in glob.glob(consolidated_jpgdir + \"*000.000..jpg\")]\n",
    "filenames = sorted(filenames)\n",
    "img = read_image(filenames[0])\n",
    "(H, W, D) = img.shape\n",
    "images = np.zeros((len(filenames), H, W, D), dtype=np.uint8)\n",
    "for i, filename in enumerate(filenames):\n",
    "    images[i,:] = read_image(filename)\n",
    "print ('[INFO] {} images loaded in {:.1f} seconds.'.format(len(filenames), (time.time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the horizontal offset from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Ground truth loaded.\n"
     ]
    }
   ],
   "source": [
    "consolidated_gtdir = '/mnt/data/style_transfers/datasets/consolidated/gt/'\n",
    "gt = np.zeros((len(filenames)), dtype=int)\n",
    "consolidated_gt = consolidated_gtdir + \"A*_GT.txt\"\n",
    "gt_filenames = [gt for gt in glob.glob(consolidated_gt)]\n",
    "gt_filenames = sorted(gt_filenames)\n",
    "for i, filename in enumerate(gt_filenames):\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = f.read()\n",
    "    data = data.split(\"\\n\")\n",
    "    data = list(filter(None, data))\n",
    "    (horizontal, _) = [int(k) for k in data[0].split(\" \")]\n",
    "    gt[i] = horizontal \n",
    "print(\"[INFO] Ground truth loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN:  -14.11731843575419 \n",
      "MEDIAN: -14.0 \n",
      "MIN: -60 \n",
      "MAX: 41\n"
     ]
    }
   ],
   "source": [
    "gt_ = list(filter(lambda x: x < 500 and x > -500, gt))\n",
    "gt_mean = np.mean([np.mean(gt__) for gt__ in gt_])\n",
    "gt_median = np.median([np.median(gt__) for gt__ in gt_])\n",
    "gt_min = np.min([np.min(gt__) for gt__ in gt_])\n",
    "gt_max = np.max([np.max(gt__) for gt__ in gt_])\n",
    "\n",
    "print('MEAN: ', gt_mean, '\\nMEDIAN:', gt_median, \"\\nMIN:\", gt_min, \"\\nMAX:\", gt_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cv2_imshow(a, title=None, mode=None, i=None, j=None, k=None, **kwargs):\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    if a.ndim == 3:\n",
    "        if a.shape[2] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "    if mode == 'subplot':\n",
    "        plt.subplot(i, j, k)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "    else:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title(title)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "def imshow(a, title=None, mode=None, i=None, j=None, k=None, **kwargs):\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    if mode == 'subplot':\n",
    "        plt.subplot(i, j, k)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "    else:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title(title)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "def process_image(img):\n",
    "    x = np.resize(img, (224,224,3))\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "def get_slices(img, offset_size, slides_count):\n",
    "    a = np.zeros((slides_count, 224, 224, 3))\n",
    "    for i in range(0, slides_count):\n",
    "        a[i,:] = process_image(img[:, offset_size*i:offset_size*i+H])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(images, base_slices, gt, offset_size, threshold):\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "    slides_count = (W - H) // offset_size\n",
    "    \n",
    "    # loop over all images\n",
    "    for traversal_idx in range(len(images)):\n",
    "        if traversal_idx % 10 == 0:\n",
    "            print(traversal_idx)\n",
    "        if traversal_idx == 0:\n",
    "            continue\n",
    "        target_gt = gt[traversal_idx]\n",
    "        if abs(target_gt) > 300:\n",
    "            continue\n",
    "        target_img = images[traversal_idx]\n",
    "        slides = get_slices(target_img, offset_size, slides_count)    \n",
    "        for j, target_slide in enumerate(slides):\n",
    "            pairImages.append([base_slices[0,0], target_slide])  # LEFT\n",
    "            pairImages.append([base_slices[1,0], target_slide])  # MIDDLE\n",
    "            pairImages.append([base_slices[2,0], target_slide])  # RIGHT\n",
    "            if abs(target_gt - j*offset_size) < threshold:     # LEFT\n",
    "                pairLabels.append([1])\n",
    "            else:\n",
    "                pairLabels.append([0])\n",
    "            if abs(250+target_gt - j*offset_size) < threshold: # MIDDLE\n",
    "                pairLabels.append([1])\n",
    "            else:\n",
    "                pairLabels.append([0])\n",
    "            if abs(500+target_gt - j*offset_size) < threshold: # RIGHT\n",
    "                pairLabels.append([1])\n",
    "            else:\n",
    "                pairLabels.append([0])\n",
    "    return (np.array(pairImages), np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the Siamese NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained VGG16 'sister' network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildVGG16_model(input_shape):\n",
    "    vgg16 = keras.applications.VGG16(weights='imagenet', include_top=True, pooling='max', input_shape=input_shape)\n",
    "    basemodel = Model(inputs=vgg16.input, outputs=vgg16.get_layer('fc2').output)\n",
    "    return basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(basemodel, img):\n",
    "    feature_vector = basemodel.predict(img)\n",
    "    return feature_vector\n",
    "def euclidean_distance(vectors):\n",
    "    (featsA, featsB) = vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,keepdims=True)\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "featureExtractor = buildVGG16_model((224,224,3))\n",
    "img1 = base_slices[0]\n",
    "img2 = base_slices[1]\n",
    "img3 = base_slices[2]\n",
    "f1 = get_feature_vector(featureExtractor, img1)\n",
    "f2 = get_feature_vector(featureExtractor, img2)\n",
    "f3 = get_feature_vector(featureExtractor, img3)\n",
    "print(euclidean_distance((f1, f1))) # 0.7384121417999268\n",
    "print(euclidean_distance((f3, f3))) # 0.48573723435401917"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(H, plotPath):\n",
    "    # construct a plot that plots and saves the training history\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_size = 2\n",
    "threshold = 1\n",
    "batch_size = 100\n",
    "epochs = 64\n",
    "IMG_SHAPE = (224,224,3)\n",
    "\n",
    "BASE_OUTPUT = \"output\"\n",
    "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"siamese_model\"])\n",
    "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img = images[0]\n",
    "base_slices = np.array([process_image(bimg) for bimg in [base_img[:,:W//3], base_img[:,W//3:(W//3)*2], base_img[:,(W//3)*2+2:]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "[INFO] 72624 pairs of image paths with offsets were generated in 124.3 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "(pairImages, pairLabels) = make_pairs(images, base_slices, gt, offset_size, threshold)\n",
    "print ('[INFO] {} pairs of image paths with offsets were generated in {:.1f} seconds.'.format(len(pairImages), (time.time()-start)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "pairTrain, labelTrain, pairTest, labelTest = train_test_split(pairImages, pairLabels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building siamese network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] building siamese network...\")\n",
    "IMG_SHAPE = (224,224,3)\n",
    "imgA = Input(shape=IMG_SHAPE)\n",
    "imgB = Input(shape=IMG_SHAPE)\n",
    "VGGfeatureExtractor = buildVGG16_model(IMG_SHAPE) # building the network only once since we want to share the weights \n",
    "featsA = VGGfeatureExtractor(imgA)\n",
    "featsB = VGGfeatureExtractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 4096)         134260544   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 134,260,546\n",
      "Trainable params: 134,260,546\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# finally, construct the siamese network\n",
    "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Epoch 1/64\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit([pairImages[:, 0], pairImages[:, 1]], pairLabels[:],\n",
    "    #validation_data=([pairTest[:, 0], pairTest[:, 1]], labelTest[:]),\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    epochs=epochs)\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving siamese model...\")\n",
    "model.save(MODEL_PATH)\n",
    "\n",
    "# plot the training history\n",
    "print(\"[INFO] plotting training history...\")\n",
    "utils.plot_training(history, PLOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#num_of_samples = features.shape[0]    \n",
    "#names = ['Correct offset', 'Wrong offset']\n",
    "#Y = np_utils.to_categorical(labels, names)\n",
    "#x,y = shuffle(features, Y, random_state=2)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model6.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:], verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing\n",
    "features = dataset_testing()\n",
    "\n",
    "num_of_samples = features.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"model6.h5\")\n",
    "names = ['Change', 'No change']\n",
    "\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "x_test,y_test = shuffle(features,Y, random_state=2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
