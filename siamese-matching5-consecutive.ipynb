{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import time\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Lambda\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import scipy.spatial.distance\n",
    "import pickle\n",
    "from scipy import interpolate\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to prepare the dataset structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(img_path):\n",
    "    img = kimage.load_img(img_path)\n",
    "    x = kimage.img_to_array(img)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_jpgdir = '/mnt/data/style_transfers/datasets/consolidated/jpg/'\n",
    "dataset_folder = \"./images_c/\"\n",
    "train_traversals = ['A000', 'A001']\n",
    "test_traversals = ['A003', 'A058', 'A059', 'A064', 'A155', 'A159', 'A035', 'A037', 'A079', 'A086', 'A150', 'A151', 'A025', 'A026', 'A062', 'A063', 'A064', 'A138', 'A007']\n",
    "test_traversals = sorted(test_traversals)\n",
    "all_traversals = [str(i) for i in range(1,179,1)]\n",
    "all_traversals = ['A'+(len(str(179))-len(digit))*'0'+digit for digit in all_traversals]\n",
    "test_filenames = np.concatenate([glob.glob(consolidated_jpgdir + i + '*..jpg') for i in test_traversals]).flat\n",
    "train_filenames = np.concatenate([glob.glob(consolidated_jpgdir + i + '*..jpg') for i in train_traversals]).flat\n",
    "test_filenames = np.concatenate([glob.glob(consolidated_jpgdir + i + '*..jpg') for i in test_traversals]).flat\n",
    "train_filenames = sorted(train_filenames)\n",
    "test_filenames = sorted(test_filenames)\n",
    "\n",
    "# in case we want to rebuild the structure, delete all the directories in './images'\n",
    "if not os.path.exists(dataset_folder + 'training'):\n",
    "    os.makedirs(dataset_folder + 'training')\n",
    "    for f in train_filenames:\n",
    "        shutil.copy(f, dataset_folder + 'training/.')\n",
    "if not os.path.exists(dataset_folder + 'testing'):\n",
    "    os.makedirs(dataset_folder + 'testing')\n",
    "    for f in test_filenames:\n",
    "        shutil.copy(f, dataset_folder + 'testing/.')\n",
    "\n",
    "img = read_image(dataset_folder + 'training/A000_000.000..jpg')\n",
    "(H, W, D) = img.shape\n",
    "print(\"[INFO] {} train images and {} test images splited into directories.\".format(len(train_traversals), len(test_traversals), len(all_traversals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the images into array (in memory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "images_train = np.zeros((len(train_filenames), H, W, D), dtype=np.uint8)\n",
    "images_test = np.zeros((len(test_filenames), H, W, D), dtype=np.uint8)\n",
    "for i, filename in enumerate(train_filenames):\n",
    "    images_train[i,:] = read_image(filename)\n",
    "for i, filename in enumerate(test_filenames):\n",
    "    images_test[i,:] = read_image(filename)\n",
    "print ('[INFO] {} images loaded in {:.1f} seconds.'.format(len(images_train)+len(images_test), (time.time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the horizontal offset from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "consolidated_gtdir = '/mnt/data/style_transfers/datasets/consolidated/gt/'\n",
    "def get_ground_truth(traversal_a, traversal_b):\n",
    "    gt = np.zeros(32, dtype=int)\n",
    "    gt_filenames = []\n",
    "    gt_filenames.append(consolidated_gtdir + traversal_a + '_GT.txt')\n",
    "    gt_filenames.append(consolidated_gtdir + traversal_b + '_GT.txt')\n",
    "    gt_filenames = sorted(gt_filenames)\n",
    "    gts = np.zeros((2,32), dtype=int)\n",
    "    gt = []\n",
    "    for i, filename in enumerate(gt_filenames):\n",
    "        data = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            data = f.read()\n",
    "        data = data.split(\"\\n\")\n",
    "        data = list(filter(None, data))\n",
    "        horizontal = [int(i.split(\" \")[0]) for i in data]\n",
    "        gts[i,:] = horizontal \n",
    "    for i in range(32):\n",
    "        gt.append(gts[1,i] - gts[0,i])\n",
    "    print(\"[INFO] Ground truth loaded.\")\n",
    "    return np.array(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_train = get_ground_truth('A000', 'A001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ = list(filter(lambda x: x < 500 and x > -500, gt_train))\n",
    "gt_mean = np.mean([np.mean(gt__) for gt__ in gt_])\n",
    "gt_median = np.median([np.median(gt__) for gt__ in gt_])\n",
    "gt_min = np.min([np.min(gt__) for gt__ in gt_])\n",
    "gt_max = np.max([np.max(gt__) for gt__ in gt_])\n",
    "\n",
    "print('MEAN: ', gt_mean, '\\nMEDIAN:', gt_median, \"\\nMIN:\", gt_min, \"\\nMAX:\", gt_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cv2_imshow(a, title=None, mode=None, i=None, j=None, k=None, **kwargs):\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    if a.ndim == 3:\n",
    "        if a.shape[2] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "    if mode == 'subplot':\n",
    "        plt.subplot(i, j, k)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "    else:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title(title)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "def imshow(a, title=None, mode=None, i=None, j=None, k=None, **kwargs):\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    if mode == 'subplot':\n",
    "        plt.subplot(i, j, k)\n",
    "        plt.title(title)\n",
    "        return plt.imshow(a, **kwargs)\n",
    "    else:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.tight_layout()\n",
    "        plt.title(title)\n",
    "        plt.imshow(a, **kwargs)\n",
    "        return plt.show()\n",
    "def process_image(img):\n",
    "    x = cv2.resize(img, (224,224))\n",
    "    return np.array(x, dtype=float)\n",
    "def get_slices(img, offset_size, slides_count):\n",
    "    a = np.zeros((slides_count, 224, 224, 3))\n",
    "    for i in range(0, slides_count):\n",
    "        a[i,:] = process_image(img[:, offset_size*i:offset_size*i+H])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(base_images, target_images, gt, offset_size, threshold):\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "    slides_count = (W - H) // offset_size\n",
    "    \n",
    "    # loop over all images\n",
    "    for seq_idx in range(32):\n",
    "        target_gt = gt[seq_idx]\n",
    "        base_image = base_images[seq_idx]\n",
    "        target_image = target_images[seq_idx]\n",
    "        base_slices = np.array([process_image(bimg) for bimg in [base_image[:,:H], base_image[:,(W-H)//2:-(W-H)//2], base_image[:,-H:]]])\n",
    "        slides = get_slices(target_image, offset_size, slides_count)    # already processed\n",
    "        for j, target_slide in enumerate(slides):\n",
    "            pairImages.append([base_slices[0], target_slide])  # LEFT\n",
    "            pairImages.append([base_slices[1], target_slide])  # MIDDLE\n",
    "            pairImages.append([base_slices[2], target_slide])  # RIGHT\n",
    "            if abs(target_gt - j*offset_size) < threshold:     # LEFT\n",
    "                pairLabels.append([1])\n",
    "            else:\n",
    "                pairLabels.append([0])\n",
    "            if abs((W-H)//2+target_gt - j*offset_size) < threshold: # MIDDLE\n",
    "                pairLabels.append([1])\n",
    "            else:\n",
    "                pairLabels.append([0])\n",
    "            if abs((W-H)+target_gt - j*offset_size) < threshold: # RIGHT\n",
    "                pairLabels.append([1])\n",
    "            else:\n",
    "                pairLabels.append([0])\n",
    "    return (np.array(pairImages), np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the Siamese NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained VGG16 'sister' network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildVGG16_model(input_shape):\n",
    "    vgg16 = keras.applications.VGG16(weights='imagenet', include_top=True, pooling='max', input_shape=input_shape)\n",
    "    basemodel = Model(inputs=vgg16.input, outputs=vgg16.get_layer('fc2').output)\n",
    "    return basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(basemodel, img):\n",
    "    feature_vector = basemodel.predict(img)\n",
    "    return feature_vector\n",
    "def euclidean_distance(vectors):\n",
    "    (featsA, featsB) = vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,keepdims=True)\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n",
    "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.dtypes.cast(y_true, y_pred.dtype)\n",
    "    return y_true * tf.math.square(y_pred) + (1.0 - y_true) * tf.math.square(tf.math.maximum(margin - y_pred, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(H, plotPath, mode='normal'):\n",
    "    if mode == 'loaded':\n",
    "        # construct a plot that plots and saves the training history\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.figure()\n",
    "        plt.plot(H[\"loss\"], label=\"train_loss\")\n",
    "        plt.plot(H[\"accuracy\"], label=\"train_acc\")\n",
    "        plt.title(\"Training Loss and Accuracy\")\n",
    "        plt.xlabel(\"Epoch #\")\n",
    "        plt.ylabel(\"Loss/Accuracy\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.savefig(plotPath)\n",
    "    else:\n",
    "        # construct a plot that plots and saves the training history\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.figure()\n",
    "        plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "        plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "        plt.title(\"Training Loss and Accuracy\")\n",
    "        plt.xlabel(\"Epoch #\")\n",
    "        plt.ylabel(\"Loss/Accuracy\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_size = 5\n",
    "threshold = offset_size * 1.3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "IMG_SHAPE = (224,224,3)\n",
    "\n",
    "BASE_OUTPUT = \"output5pxc\"\n",
    "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"siamese_model\"])\n",
    "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "(pairTrain, labelsTrain) = make_pairs(images_train[:32], images_train[32:], gt_train, offset_size, threshold)\n",
    "print ('[INFO] {} pairs of image paths with offsets were generated in {:.1f} seconds.'.format(len(pairTrain), (time.time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] building siamese network...\")\n",
    "IMG_SHAPE = (224,224,3)\n",
    "imgA = Input(shape=IMG_SHAPE)\n",
    "imgB = Input(shape=IMG_SHAPE)\n",
    "VGGfeatureExtractor = buildVGG16_model(IMG_SHAPE) # building the network only once since we want to share the weights \n",
    "featsA = VGGfeatureExtractor(imgA)\n",
    "featsB = VGGfeatureExtractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, construct the siamese network\n",
    "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = BASE_OUTPUT + \"/training/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "#model.load_weights(checkpoint_path)\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)\n",
    "\n",
    "def merge_dicts(d1, d2):\n",
    "    d = {}\n",
    "    for key in d1.keys():\n",
    "        l1 = d1[key]\n",
    "        l2 = d2[key]\n",
    "        d[key] = l1 + l2\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit([pairTrain[:, 0], pairTrain[:, 1]], labelsTrain[:],\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    epochs=epochs,\n",
    "    callbacks=[cp_callback])\n",
    "\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(MODEL_PATH + \"/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(MODEL_PATH + \"/model_weights.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# plot the training history\n",
    "print(\"[INFO] plotting current training history...\")\n",
    "plot_training(history, PLOT_PATH)\n",
    "\n",
    "# merge with existing training and save it\n",
    "loaded_history = pickle.load(open(BASE_OUTPUT + '/trainHistoryDict', \"rb\"))\n",
    "new_history = merge_dicts(loaded_history, history.history)\n",
    "print(\"[INFO] plotting the whole training history...\")\n",
    "plot_training(new_history, PLOT_PATH, \"loaded\")\n",
    "\n",
    "with open(BASE_OUTPUT + '/trainHistoryDict', 'wb') as file_pi:\n",
    "    pickle.dump(new_history, file_pi)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(MODEL_PATH + \"/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(MODEL_PATH + \"/model_weights.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# plot the training history\n",
    "print(\"[INFO] plotting current training history...\")\n",
    "plot_training(history, PLOT_PATH)\n",
    "\n",
    "# merge with existing training and save it\n",
    "loaded_history = pickle.load(open(BASE_OUTPUT + '/trainHistoryDict', \"rb\"))\n",
    "new_history = merge_dicts(loaded_history, history.history)\n",
    "print(\"[INFO] plotting the whole training history...\")\n",
    "plot_training(new_history, PLOT_PATH, \"loaded\")\n",
    "\n",
    "with open(BASE_OUTPUT + '/trainHistoryDict', 'wb') as file_pi:\n",
    "    pickle.dump(new_history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open(MODEL_PATH + '/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(MODEL_PATH + \"/model_weights.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "h = {'loss': [],\n",
    " 'accuracy': []}\n",
    "with open('output5pxc/trainHistoryDict', 'wb') as file_pi:\n",
    "    pickle.dump(h, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_offsets(model, base_images, target_images, base_part, slides_count, offset_size):\n",
    "    sims = np.zeros((len(base_images), slides_count, 1))\n",
    "    for i in range(len(base_images)):\n",
    "        base_image = base_images[i]\n",
    "        target_image = target_images[i]\n",
    "        base_slices = np.array([process_image(bimg) for bimg in [base_image[:,:H], base_image[:,(W-H)//2:-(W-H)//2], base_image[:,-H:]]], dtype=float)\n",
    "        target_slices = get_slices(target_image, offset_size, slides_count)\n",
    "        base_slices_ = np.array([base_slices[base_part] for _ in range(slides_count)])\n",
    "        pair = [base_slices_, target_slices]\n",
    "        similarity = model.predict(pair)\n",
    "        sims[i,:] = similarity\n",
    "    return np.array(sims)\n",
    "def get_offsets_(model, base_slices, target_images, base_part, slides_count, offset_size):\n",
    "    sims = np.zeros((len(target_images), slides_count, 1))\n",
    "    for i in range(len(target_images)):\n",
    "        target_image = target_images[i]\n",
    "        target_slices = get_slices(target_image, offset_size, slides_count)\n",
    "        base_slices_ = np.array([base_slices[base_part] for _ in range(slides_count)])\n",
    "        pair = [base_slices_, target_slices]\n",
    "        similarity = model.predict(pair)\n",
    "        sims[i,:] = similarity\n",
    "    return np.array(sims)\n",
    "def closest_number(n, m) : \n",
    "    q = int(n / m) \n",
    "    n1 = m * q \n",
    "    if((n * m) > 0) : \n",
    "        n2 = (m * (q + 1))  \n",
    "    else : \n",
    "        n2 = (m * (q - 1)) \n",
    "    if (abs(n - n1) < abs(n - n2)) : \n",
    "        return n1       \n",
    "    return n2 \n",
    "def show_offsets(base_images, target_images, similarities, gt, traversal_names_a, traversal_names_b, base_part, offset_size, top_n):\n",
    "    gt_offsets = [0, (W-H)//2,(W-H)]\n",
    "    line_separator = \"---------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "    parts = [\"LEFT\", \"CENTER\", \"RIGHT\"]\n",
    "    if(base_part < 3):\n",
    "        print(\"PREDICTIONS FOR THE \" + parts[base_part] + \" PART OF THE BASE IMAGE:\\n\\n\")\n",
    "        for i, similarity in enumerate(similarities):\n",
    "            print(line_separator + \"Test image \", traversal_names[i], \"\\n\")\n",
    "            print(gt[i] + gt_offsets[base_part], \"    true offset (in px)\")\n",
    "            print(np.argmax(similarity) * offset_size, '     predicted offset (in px)\\n')\n",
    "    else:\n",
    "        print(\"PREDICTIONS FOR ALL PARTS OF THE BASE IMAGE:\\n\\n\")\n",
    "        space_separator = \"                    |                    \"\n",
    "        small_separator = \"     |     \"\n",
    "        tiny_separator = \"  |  \"\n",
    "        print(parts[0] + space_separator + parts[1] + space_separator + parts[2] + \"\\n\" + line_separator)\n",
    "        for i in range(len(similarities)):\n",
    "            base_image = base_images[i]\n",
    "            target_image = target_images[i]\n",
    "            print(line_separator + \"Pair\", traversal_names_a[i][-17:-5], \":\", traversal_names_b[i][-17:-5], \"\\n\")\n",
    "            plt.figure(figsize=(8,4))\n",
    "            plt.tight_layout()\n",
    "            imshow(base_image, 'base image', 'subplot', 1, 2, 1)\n",
    "            imshow(target_image, 'target image', 'subplot', 1, 2, 2)\n",
    "            plt.show()\n",
    "            print(\"True offset:     \" + str(gt[i])) \n",
    "            left = similarities[i,0,:]\n",
    "            center = similarities[i,1,:]\n",
    "            right = similarities[i,2,:]\n",
    "            sorted_left = (-left).argsort()[:top_n] * offset_size - gt_offsets[0]\n",
    "            sorted_center = (-center).argsort()[:top_n] * offset_size - gt_offsets[1]\n",
    "            sorted_right = (-right).argsort()[:top_n] * offset_size - gt_offsets[2]\n",
    "            rounded_left = [closest_number(n, offset_size) for n in sorted_left]\n",
    "            rounded_center = [closest_number(n, offset_size) for n in sorted_center]\n",
    "            rounded_right = [closest_number(n, offset_size) for n in sorted_right]\n",
    "            print(\"Predicted offsets:\")\n",
    "            print(parts[0] + space_separator + parts[1] + small_separator + parts[2] + \"\\n\" + line_separator)\n",
    "            print(str(rounded_left) + small_separator + \"  \" + \n",
    "                  str(rounded_center) + small_separator +\n",
    "                  str(rounded_right))\n",
    "            counter = Counter(rounded_left + rounded_center + rounded_right)\n",
    "            (val, cnt) = counter.most_common(1)[0]\n",
    "            print(\"Most frequent offset: \", val)\n",
    "def process_offsets(similarities, offset_size, sliced_count):\n",
    "    gt_offsets = [0, (W-H)//2,(W-H)]\n",
    "    offsets = np.zeros((len(similarities), len(similarities[0]), slides_count)) # 3 x 32 x 'slides_count'\n",
    "    # Iterate throught target images...\n",
    "    for i in range(len(similarities)):\n",
    "        left = similarities[i,0,:]\n",
    "        center = similarities[i,1,:]\n",
    "        right = similarities[i,2,:]\n",
    "        sorted_left = (-left).argsort() * offset_size - gt_offsets[0]\n",
    "        sorted_center = (-center).argsort() * offset_size - gt_offsets[1]\n",
    "        sorted_right = (-right).argsort() * offset_size - gt_offsets[2]\n",
    "        rounded_left = [closest_number(n, offset_size) for n in sorted_left]\n",
    "        rounded_center = [closest_number(n, offset_size) for n in sorted_center]\n",
    "        rounded_right = [closest_number(n, offset_size) for n in sorted_right]  \n",
    "        offsets[i,0,:] = sorted_left\n",
    "        offsets[i,1,:] = rounded_center\n",
    "        offsets[i,2,:] = rounded_right\n",
    "    return offsets\n",
    "            \n",
    "def save_offsets(offsets, filename):\n",
    "    with open(BASE_OUTPUT + \"/\" + filename, 'wb') as file_pi:\n",
    "        pickle.dump(offsets, file_pi)\n",
    "    print(\"[INFO] Offsets pickled into file '\" + filename + \"'.\")\n",
    "def load_offsets(filepath):\n",
    "    return pickle.load(open(filepath, \"rb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "slides_count = (W - H) // offset_size\n",
    "fst_traversal = 'A000'\n",
    "snd_traversal = 'A001'\n",
    "\n",
    "gt_test = get_ground_truth(fst_traversal, snd_traversal)\n",
    "center_offsets = get_offsets(model, images_train[:32], images_train[32:], 1, slides_count, offset_size)\n",
    "\n",
    "print ('[INFO] For 1 position, the offsets were predicted in {:.1f} seconds.'.format((time.time()-start)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "top_n = 3\n",
    "all_offsets = np.zeros((len(left_offsets), 3, slides_count))\n",
    "for t in range(len(left_offsets)):\n",
    "    all_offsets[t,0,:] = left_offsets[t,:,0]\n",
    "    all_offsets[t,1,:] = center_offsets[t,:,0]\n",
    "    all_offsets[t,2,:] = right_offsets[t,:,0]\n",
    "show_offsets(images_train[:32], images_train[32:], all_offsets, gt_test, train_filenames[:32], train_filenames[32:], 3, offset_size, top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Testing Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. load images from 'positioned' directory\n",
    "2. take the first as a base image and compute the predicted offsets for all images\n",
    "3. save the offset into 'results' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultsDir = \"./results/\"\n",
    "offset_size = 5\n",
    "model_type_flag = \"cspline\"\n",
    "first_time = True\n",
    "slides_count = (W-H) // offset_size\n",
    "fst_traversal = 'A000'\n",
    "spc = \"   |   \"\n",
    "big_spc = \"         |        \"\n",
    "\n",
    "# load all offsets\n",
    "traversals = os.listdir(\"./positioned/1/\")\n",
    "traversals = [f[:4] for f in traversals]\n",
    "traversals = sorted(traversals)\n",
    "center_bins = np.array([i for i in range(slides_count)]) * offset_size - (W-H)//2\n",
    "\n",
    "sims_idx = np.array([i if abs(b) > 30 else -1  for i, b in enumerate(center_bins)])\n",
    "sims_idx = np.where(sims_idx != -1)\n",
    "\n",
    "if(traversals[0] != fst_traversal):\n",
    "    print(\"[ERROR] The base image A000 has to be at the first place!\")\n",
    "    \n",
    "offsets = np.zeros((len(traversals)-1, 32, slides_count, 1))\n",
    "target_traversals = traversals[1:]\n",
    "for i, snd_traversal in enumerate(target_traversals):\n",
    "    offsetsDir = BASE_OUTPUT + '/offsets/' + fst_traversal + '-' + snd_traversal\n",
    "    current_traversal_offsets = load_offsets(offsetsDir)\n",
    "    offsets[i,:] = current_traversal_offsets\n",
    "gts = np.zeros((len(target_traversals), 32))\n",
    "for i in range(len(gts)):\n",
    "    gts[i] = get_ground_truth(fst_traversal, target_traversals[i])\n",
    "    \n",
    "#get the peak of similarities for each of the position and each of the traversals, then save it into 'results' dir\n",
    "for files in os.walk(\"./positioned/\"):\n",
    "    start = time.time()\n",
    "    if files[0] == \"./positioned/\":\n",
    "        continue\n",
    "    \n",
    "    position = files[0].split(\"/\")[-1]\n",
    "    print(\"==============\")\n",
    "    print(\"Position: \" + str(position))\n",
    "    print(\"==============\")\n",
    "    filenames = files[2]  # A000_000.000-xx.bmp etc.\n",
    "    filenames = sorted(filenames)\n",
    "    \n",
    "    # Build results directories if not done yet\n",
    "    if first_time:\n",
    "        try:\n",
    "            for j in range(1, 33):\n",
    "                Path(resultsDir + \"snn_\" + str(offset_size) + \"px\" + model_type_flag + \"/\" + str(j)).mkdir(parents=True, exist_ok=True)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        first_time = False\n",
    "        \n",
    "    # Get the most promising offset from these and save it into results directory\n",
    "    print(\"Predicted offsets:\")\n",
    "    print(\"POSITION\" + spc + \"TRAVERSAL\" + spc + \"PEAK\" + big_spc + \"PEAK VAL\" + spc + \"SPLINE PEAK\" + spc + \"SPLINE PEAK VAL\" + spc + \"GT\")\n",
    "    for i, traversal_offsets in enumerate(offsets):\n",
    "        similarities = traversal_offsets[int(position)-1,:,0]\n",
    "        # 1. get the histogram RAW data peak\n",
    "        similarities[sims_idx] = 0\n",
    "        peak_idx = np.argmax(similarities)\n",
    "        peak = center_bins[peak_idx]\n",
    "        peak_val = np.max(similarities)\n",
    "        \n",
    "        # 2. get the spline peak\n",
    "        tck,_     = interpolate.splprep( [center_bins, similarities] ,s = 10)\n",
    "        spline_bins,spline = interpolate.splev( np.linspace( 0, 1, 1000), tck, der = 0)\n",
    "        spline[sims_idx] = -1\n",
    "        spline_peak_idx = np.argmax(spline)\n",
    "        spline_peak = int(spline_bins[spline_peak_idx])\n",
    "        spline_peak_val = np.max(spline)\n",
    "        \n",
    "        print(str(position) + big_spc + str(target_traversals[i]) + spc + str(peak) + big_spc + str(peak_val)[:5] + spc + str(spline_peak) + big_spc + str(spline_peak_val)[:5] + big_spc + str(gts[i,int(position)-1]))\n",
    "        fn = os.path.join(resultsDir + \"snn_\" + str(offset_size) + \"px\" + model_type_flag + \"/\" + str(position), filenames[i+1] + \".best\")\n",
    "        with open(fn, \"w\") as f:\n",
    "            f.write(str(spline_peak) + \"\\n\")\n",
    "    print ('[INFO] On position #{}, the offsets were predicted in {:.1f} seconds.'.format(position, (time.time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Interpret the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate a histogram from similarities with center part of the base image\n",
    "2. Plot it with and without using spline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "slides_count = (W - H) // offset_size\n",
    "fst_traversal = 'A000'\n",
    "snd_traversal = 'A005'\n",
    "\n",
    "gt_test = get_ground_truth(fst_traversal, snd_traversal)\n",
    "center_offsets = get_offsets(model, images_train[:1*32], images_test[3*32:4*32], 1, slides_count, offset_size)\n",
    "\n",
    "offsetsDir =  '/offsets/' + fst_traversal + '-' + snd_traversal\n",
    "save_offsets(center_offsets, offsetsDir)\n",
    "center_bins = np.array([i for i in range(slides_count)]) * offset_size - (W-H)//2\n",
    "print ('[INFO] For 1 position, the offsets were predicted in {:.1f} min.'.format((time.time()-start) // 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute offsets for all selected traversals:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "slides_count = (W - H) // offset_size\n",
    "fst_traversal = 'A000'\n",
    "for i, snd_traversal in enumerate(traversals):\n",
    "    gt_test = get_ground_truth(fst_traversal, snd_traversal)\n",
    "    center_offsets = get_offsets(model, images_train[:32], images_test[i*32:(i+1)*32,:], 1, slides_count, offset_size)\n",
    "\n",
    "    offsetsDir =  '/offsets/' + fst_traversal + '-' + snd_traversal\n",
    "    save_offsets(center_offsets, offsetsDir)\n",
    "    center_bins = np.array([i for i in range(slides_count)]) * offset_size - (W-H)//2\n",
    "    print ('[INFO] For traversal {}, the offsets were predicted in {:.1f} seconds.'.format(snd_traversal, (time.time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load offsets from a file and save the plot to a file:\n",
    "* get number of base traversal and target traversal as an input\n",
    "* load offsets from these traversals\n",
    "* plot the offsets for all positions and save the images with plot to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_traversals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "slides_count = (W - H) // offset_size\n",
    "fst_traversal = 'A000'\n",
    "snd_traversal = 'A059'\n",
    "plotDir = BASE_OUTPUT + '/plots/' + fst_traversal + '-' + snd_traversal + '/'\n",
    "offsetsDir = BASE_OUTPUT + '/offsets/' + fst_traversal + '-' + snd_traversal\n",
    "Path(plotDir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "center_offsets = load_offsets(offsetsDir)\n",
    "center_bins = np.array([i for i in range(slides_count)]) * offset_size - (W-H)//2\n",
    "gt_test = get_ground_truth(fst_traversal, snd_traversal)\n",
    "\n",
    "fst_traversal_images = images_train[:32]\n",
    "fst_traversal_names = train_filenames[:32]\n",
    "snd_index = test_traversals.index(snd_traversal)\n",
    "snd_traversal_images = images_test[snd_index*32:(snd_index+1)*32]\n",
    "snd_traversal_names = test_filenames[snd_index*32:(snd_index+1)*32]\n",
    "\n",
    "for image_index in range(0,32,1):\n",
    "    similarity = center_offsets[image_index,:,0]\n",
    "    tck,u     = interpolate.splprep( [center_bins, similarity] ,s = 10)\n",
    "    xnew,ynew = interpolate.splev( np.linspace( 0, 1, 1000), tck, der = 0)\n",
    "    true_offset = gt_test[image_index]\n",
    "    rounded_offset = closest_number(true_offset, offset_size) - 1\n",
    "    if(rounded_offset > center_bins[-1] or rounded_offset < center_bins[0]):\n",
    "        print('The offset {} is too big/small for the trained network.'.format(rounded_offset))\n",
    "        continue\n",
    "    plt.figure(figsize=(16,8))\n",
    "    imshow(fst_traversal_images[image_index], 'Image ' + fst_traversal_names[image_index][-17:-5], 'subplot', 1,3,1)\n",
    "    imshow(snd_traversal_images[image_index], 'Image ' + snd_traversal_names[image_index][-17:-5], 'subplot', 1,3,2)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(center_bins, similarity, color='r')\n",
    "    plt.plot(xnew, ynew, color='b')\n",
    "    plt.plot(rounded_offset, similarity[np.where(center_bins == rounded_offset)], 'o', color='black')\n",
    "    plt.legend( [ 'data' , 'spline', 'GT'] )\n",
    "    plt.axvline(x=rounded_offset, color='black')\n",
    "    plt.title('GT is {} px offset, {} px offset has similarity {:.2f}'.format(true_offset, rounded_offset, similarity[np.where(center_bins == rounded_offset)][0]))\n",
    "    plt.grid()\n",
    "    plotPath = plotDir + train_filenames[image_index][-12:-5] + \".png\"\n",
    "    plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slides_count = (W - H) // offset_size\n",
    "center_bins = np.array([i for i in range(slides_count)]) * offset_size - (W-H)//2\n",
    "fst_traversal = 'A000'\n",
    "for snd_traversal in test_traversals:\n",
    "    plotDir = BASE_OUTPUT + '/plots/' + fst_traversal + '-' + snd_traversal + '/'\n",
    "    offsetsDir = BASE_OUTPUT + '/offsets/' + fst_traversal + '-' + snd_traversal\n",
    "    Path(plotDir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    center_offsets = load_offsets(offsetsDir)\n",
    "    gt_test = get_ground_truth(fst_traversal, snd_traversal)\n",
    "\n",
    "    fst_traversal_images = images_train[:32]\n",
    "    fst_traversal_names = train_filenames[:32]\n",
    "    snd_index = test_traversals.index(snd_traversal)\n",
    "    snd_traversal_images = images_test[snd_index*32:(snd_index+1)*32]\n",
    "    snd_traversal_names = test_filenames[snd_index*32:(snd_index+1)*32]\n",
    "\n",
    "    for image_index in range(0,32,1):\n",
    "        similarity = center_offsets[image_index,:,0]\n",
    "        tck,u     = interpolate.splprep( [center_bins, similarity] ,s = 0.01)\n",
    "        xnew,ynew = interpolate.splev( np.linspace( 0, 1, 200), tck, der = 0)\n",
    "        true_offset = gt_test[image_index]\n",
    "        rounded_offset = closest_number(true_offset, offset_size) - 1\n",
    "        if(rounded_offset > center_bins[-1] or rounded_offset < center_bins[0]):\n",
    "            print('The offset {} is too big/small for the trained network.'.format(rounded_offset))\n",
    "            continue\n",
    "        plt.figure(figsize=(16,8))\n",
    "        imshow(fst_traversal_images[image_index], 'Image ' + fst_traversal_names[image_index][-17:-5], 'subplot', 1,3,1)\n",
    "        imshow(snd_traversal_images[image_index], 'Image ' + snd_traversal_names[image_index][-17:-5], 'subplot', 1,3,2)\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.plot(center_bins, similarity, color='r')\n",
    "        plt.plot(xnew, ynew, color='b')\n",
    "        plt.plot(rounded_offset, similarity[np.where(center_bins == rounded_offset)], 'o', color='black')\n",
    "        plt.legend( [ 'data' , 'spline', 'GT'] )\n",
    "        plt.axvline(x=rounded_offset, color='black')\n",
    "        plt.title('GT is {} px offset, {} px offset has similarity {:.2f}'.format(true_offset, rounded_offset, similarity[np.where(center_bins == rounded_offset)][0]))\n",
    "        plt.grid()\n",
    "        plotPath = plotDir + train_filenames[image_index][-12:-5] + \".png\"\n",
    "        plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show plots from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slides_count = (W - H) // offset_size\n",
    "center_bins = np.array([i for i in range(slides_count)]) * offset_size - (W-H)//2\n",
    "fst_traversal = 'A000'\n",
    "snd_traversal = 'A059'\n",
    "plotDir = BASE_OUTPUT + '/plots/' + fst_traversal + '-' + snd_traversal + '/'\n",
    "plotPath = plotDir + train_filenames[image_index][-12:-5] + \".png\"\n",
    "plot = read_image(plotPath)\n",
    "cv2.imshow('title', plot)\n",
    "imshow(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
